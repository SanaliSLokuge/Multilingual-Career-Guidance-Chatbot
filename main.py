# main.py
import streamlit as st
from openai import OpenAI

# âœ… Load SUTRA API key securely
api_key = st.secrets["SUTRA_API_KEY"]

# âœ… Initialize Sutra-compatible client
client = OpenAI(
    base_url="https://api.two.ai/v2",
    api_key=api_key
)

# âœ… Page config
st.title("ğŸ“ Multilingual Career Counselor (SUTRA AI)")
st.markdown("Ask any career-related question in your native language and get personalized advice.")

# âœ… Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system",
            "content": (
                "You are a multilingual career advisor. "
                "Always reply in the same language as the user. "
                "Provide career advice, suggest learning paths, course options, university suggestions, and affordable alternatives. "
                "Handle follow-up questions like 'Can I do this without a degree?' or 'Where can I study abroad?'."
            )
        }
    ]
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # list of (user_message, assistant_reply)

# âœ… User input for new or first question
user_input = st.text_input("ğŸ“ What's your career goal, interest, or question?", key="main_input")

# âœ… Handle initial question
if st.button("Get Advice", key="submit_main"):
    if user_input.strip():
        st.session_state.messages.append({"role": "user", "content": user_input})

        with st.spinner("Generating advice..."):
            stream = client.chat.completions.create(
                model="sutra-v2",
                messages=st.session_state.messages,
                temperature=0.7,
                max_tokens=700,
                stream=True
            )

            full_response = ""
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    # Optional: real-time update
                    st.markdown(full_response + "â–Œ")

            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.session_state.chat_history.append((user_input, full_response))
    else:
        st.warning("Please enter a career question.")

# âœ… Follow-up input
followup_input = st.text_input("ğŸ’¡ Ask a follow-up (e.g., 'Can I do it without a degree?')", key="followup_input")

# âœ… Handle follow-up
if st.button("Ask Follow-Up", key="submit_followup"):
    if followup_input.strip():
        st.session_state.messages.append({"role": "user", "content": followup_input})

        with st.spinner("Following up..."):
            stream = client.chat.completions.create(
                model="sutra-v2",
                messages=st.session_state.messages,
                temperature=0.7,
                max_tokens=700,
                stream=True
            )

            full_response = ""
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    # Optional: real-time update
                    st.markdown(full_response + "â–Œ")

            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.session_state.chat_history.append((followup_input, full_response))
    else:
        st.warning("Enter a follow-up question.")

# âœ… Display full chat history
st.markdown("---")
st.subheader("ğŸ“œ Conversation History")
for i, (user_q, bot_a) in enumerate(st.session_state.chat_history):
    st.markdown(f"**You:** {user_q}")
    st.markdown(f"**Sutra:** {bot_a}")
    st.markdown("---")

# âœ… Reset chat option
if st.button("ğŸ” Reset Conversation"):
    st.session_state.messages = st.session_state.messages[:1]
    st.session_state.chat_history = []
    st.success("Chat history cleared.")
